{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CyberGIS-Compute FireABM Monte Carlo Notebook\n",
    "\n",
    "**Author**: Rebecca Vandewalle rcv3@illinois.edu\n",
    "<br>**Created**: 8-16-21\n",
    "\n",
    "This notebook provides an example of running a Monte Carlo style computation using CyberGIS-Compute. CyberGIS-Compute is service for running High Performance Computing (HPC) jobs from a Jupyter Notebook within CyberGISX. In this example, the FireABM simulation script is run twice, each separately using two different tasks. This small example demonstrates how to run a serial script with no in-built parallelization multiple times on CyberGIS-Compute, how to pass parameters from a notebook to CyberGIS-Compute, how to access standard HPC variables (such as node_ids) from within a CyberGIS-Compute job, and how to specify the correct working and results directories for running the job script and downloading the results. The goal of this example is to demonstrate how to use CyberGIS-Compute with no or very little adjustments to the original serial script. The custom job in this notebook uses this repository: https://github.com/cybergis/cybergis-compute-fireabm.git ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Load the CyberGIS-Compute Client](#load)\n",
    "- [Prepare the GitHub Repository](#prepare)\n",
    "- [Setup the CyberGIS-Compute Job](#setup)\n",
    "- [Run the CyberGIS-Compute Job](#view)\n",
    "- [View and Download the CyberGIS-Compute Job Results](#run)\n",
    "- [Clean up](#clean)\n",
    "- [Steps for Creating your own Custom job](#create)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## Load the CyberGIS-Compute Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CyberGIS-Compute client is the middleware that makes it possible to access High Performance Computing (HPC) resources from within a CyberGISX Jupyter Notebook. The first cell loads the client if it has already been installed. If not, it first installs the client and then loads it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load CyberGIS-Compute client\n",
    "\n",
    "try:\n",
    "    from cybergis_compute_client import CyberGISCompute\n",
    "    \n",
    "# If not already setup, setup CyberGIS-Compute in the current Jupyter kernel\n",
    "\n",
    "except:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install git+https://github.com/cybergis/job-supervisor-python-sdk.git@v2\n",
    "    from cybergis_compute_client import CyberGISCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare\"></a>\n",
    "## Prepare the GitHub Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom repository used in this example is https://github.com/cybergis/cybergis-compute-fireabm.git .\n",
    "\n",
    "This repo contains the following files:\n",
    "- **README.md**: a readme to give information about the repo\n",
    "- **manifest.json**: a file that controls how the CyberGIS-Compute is run\n",
    "- **runjobs.sh**: a shell script that creates needed directories and runs run_fireabm.py\n",
    "- **run_fireabm.py**: the top level python script that runs the simulation\n",
    "- other files and directories: contain data and functions needed to run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**manifest.json** (https://github.com/cybergis/cybergis-compute-fireabm/blob/main/manifest.json) is a mandatory file. It must be a JSON file named manifest.json and must contain a JSON array of key value pairs that are used by CyberGIS-Compute. In particutlar, the \"name\" value must be set, the \"container\" must be set (\"cybergisx-0.4\" contains the same modules as a CyberGISX notebook at the time this tutorial notebook was created), and the \"execution_stage\" must be set. In this case \"bash ./runjobs.sh\" tells CyberGIS-Compute to run the shell script `runjobs.sh` when the job runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**runjobs.sh** (https://github.com/cybergis/cybergis-compute-fireabm/blob/main/runjobs.sh) is a shell script that runs when a CyberGIS-Compute Job is run. This script does the following actions:\n",
    "- sets a `$SEED` variable value based on the `$param_start_value` (a value set when the job is constructed within this Notebook) and `#SLURM_PROCID` (the task ID, a built in variable populated when the job runs on HPC)\n",
    "- creates a directory in the `$result_folder` (a path set by the CyberGIS-Compute Client when the job is created)\n",
    "- on one task only: copies files to the `$result_folder`\n",
    "- runs the python script run_fireabm.py (the serial starting script) passing in the `$SEED` value and the `$result_folder value`\n",
    "- on one task only: after the script is run, removes data files from the `$result_folder` (note that for real examples, this task is better done in the `post_processing_stage`\n",
    "\n",
    "**Variables**: This shell script uses variables and directories set in a few different places. The `$SEED` variable is created in runjobs.sh. The `$param_start_value` is a value that is passed to the CyberGIS-Compute client from a notebook. This value is set in the `param` array within the `.set()` function in the next section of this notebook. `#SLURM_PROCID` is a built-in variable set on the HPC (other available variables can be found here: https://slurm.schedmd.com/srun.html#lbAJ)\n",
    "\n",
    "**Directories**: CyberGIS-Compute client uses two primary directories which are set when the job is created. The paths to these directories can be accessed by environment variables. Although scripts are run in the `$executable_folder`, results should be written to the `$results_folder`. These folders are not in the same location. You might need to adjust your primary script if it by default writes result files in the same folder as the script. In this example, the `$results_folder` variable is passed to the python script, which requires an output path to use to write results.\n",
    "\n",
    "**Execution Stages**: The CyberGIS-Compute client supports three stages: \"pre_processing_stage\", \"execution_stage\", and \"post_processing_stage\". These are each keys in the manifest.json file which expect a command to run as a value. An example of a manifest.json file that uses all three stages can be found here: https://github.com/cybergis/cybergis-compute-hello-world/blob/main/manifest.json . Ideally the clean up tasks should be performed in the \"post_processing_stage\" to ensure that all tasks in the execution stage are finished before performing clean up activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other files and directories in the repo**: The FireABM simulation needs some small input data files and a specific input directory structure. These files and directories are included in the GitHub repo and will be copied to the `$executable_folder` by the CyberGIS-Compute Client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup the CyberGIS-Compute Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, a CyberGIS-Compute object and a job object is created. See this tutorial notebook for more details on the basic job creation process: https://cybergisxhub.cigi.illinois.edu/notebook/cybergis-compute-tutorial/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CyberGIS-Compute object\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup-dev.cigi.illinois.edu\", \n",
    "                           port=3030, protocol='HTTP', isJupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a custom job, the maintainer will be \"community_contribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align:left\">maintainer             </th><th style=\"text-align:left\">hpc                                       </th><th style=\"text-align:left\">default_hpc      </th><th style=\"text-align:left\">job_pool_capacity  </th><th style=\"text-align:left\">executable_folder-&gt;from_user  </th><th style=\"text-align:left\">executable_folder-&gt;must_have  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align:left\">hello_world_singularity</td><td style=\"text-align:left\">[&#x27;keeling_community&#x27;]                     </td><td style=\"text-align:left\">keeling_community</td><td style=\"text-align:left\">5                  </td><td style=\"text-align:left\">False                         </td><td style=\"text-align:left\">not specified                 </td></tr>\n",
       "<tr><td style=\"text-align:left\">community_contribution </td><td style=\"text-align:left\">[&#x27;keeling_community&#x27;, &#x27;bridges_community&#x27;]</td><td style=\"text-align:left\">keeling_community</td><td style=\"text-align:left\">5                  </td><td style=\"text-align:left\">True                          </td><td style=\"text-align:left\">not specified                 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List available maintainers\n",
    "\n",
    "cybergis.list_maintainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each custom job requires a GitHub repository to be created and specified when the job is created. After the GitHub repository is created, the CyberGISX team must be contacted to review the repository and if approved, add it to the available repositories that can be used with CyberGIS-Compute. In this case the custom repository described above can be seen in the approved repositories list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align:left\">link                         </th><th style=\"text-align:left\">name                          </th><th style=\"text-align:left\">container    </th><th style=\"text-align:left\">repository                                                              </th><th style=\"text-align:left\">commit  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align:left\">git://spatial_access_covid-19</td><td style=\"text-align:left\">COVID-19 spatial accessibility</td><td style=\"text-align:left\">python       </td><td style=\"text-align:left\">https://github.com/cybergis/cybergis-compute-spatial-access-covid-19.git</td><td style=\"text-align:left\">        </td></tr>\n",
       "<tr><td style=\"text-align:left\">git://hello_world            </td><td style=\"text-align:left\">hello world                   </td><td style=\"text-align:left\">python       </td><td style=\"text-align:left\">https://github.com/cybergis/cybergis-compute-hello-world.git            </td><td style=\"text-align:left\">        </td></tr>\n",
       "<tr><td style=\"text-align:left\">git://fireabm                </td><td style=\"text-align:left\">hello FireABM                 </td><td style=\"text-align:left\">cybergisx-0.4</td><td style=\"text-align:left\">https://github.com/cybergis/cybergis-compute-fireabm.git                </td><td style=\"text-align:left\">        </td></tr>\n",
       "<tr><td style=\"text-align:left\">git://bridge_hello_world     </td><td style=\"text-align:left\">hello world                   </td><td style=\"text-align:left\">python       </td><td style=\"text-align:left\">https://github.com/cybergis/CyberGIS-Compute-Bridges-2.git              </td><td style=\"text-align:left\">        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List available git repositories\n",
    "\n",
    "cybergis.list_git()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a 'community_contribution' job object can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ƒ created constructor file [job_constructor_16291420382ZGRa.json]\n"
     ]
    }
   ],
   "source": [
    "# Create base job object\n",
    "\n",
    "demo_job = cybergis.create_job('community_contribution', hpc='keeling_community')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run\"></a>\n",
    "## Run the CyberGIS-Compute Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.set()` function can accept an array of keys that can be used to set common HPC variables. Supported keys are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that can be set\n",
    "\n",
    "# slurm = {\n",
    "#    walltime?: string -> --time\n",
    "#    num_of_node?: number -> --nodes\n",
    "#    num_of_task?: number -> --ntasks\n",
    "#    cpu_per_task?: number -> --cpus-per-task\n",
    "#    memory?: string -> --mem\n",
    "#    memory_per_cpu?: string -> --mem-per-cpu\n",
    "#    memory_per_gpu?: string -> --mem-per-gpu\n",
    "#    gpus?: number -> --gpus\n",
    "#    gpus_per_node?: number | string -> --gpus-per-node\n",
    "#    gpus_per_socket?: number | string -> --gpus-per-socket\n",
    "#    gpus_per_task?: number | string -> --gpus-per-task\n",
    "#    partition?: string -> --partition\n",
    "#    mail_type?: string[] -> --mail-type (ex. \"mail_type\": [\"END\", \"FAIL\"])\n",
    "#    mail_user?: string[] -> --mail-user (ex. \"mail_user\": [\"email@email.com\"])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now job specific parameters are set for the job. The `slurm` array sets HPC values. The `param` array is used to set a custom variable required by the `runjobs.sh` shell script. Note that in the `param` array, the variable is set to the key `start_value`, which is accessed in runjobs.sh as `$param_start_value`. \n",
    "\n",
    "The `slurm` `\"num_of_task\"` key value sets the number of tasks requested by the CyberGIS-Compute client when the job runs on HPC. This means that the `runjobs.sh` shell script will be run twice, once per each task. In the `runjobs.sh` shell script, the `#SLURM_PROCID` variable, a unique id that is given to each task, is used to differentiate between the two times the `run_fireabm.py` script is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'param': {'start_value': 20}, 'env': {}, 'slurm': {'num_of_task': 2, 'walltime': '10:00'}, 'executableFolder': 'git://fireabm'}\n"
     ]
    }
   ],
   "source": [
    "# Set number of tasks and the starting value for the script\n",
    "\n",
    "task_number = 2\n",
    "local_start_value = 20\n",
    "\n",
    "# Sets variables used by HPC\n",
    "\n",
    "slurm = {\n",
    "    \"num_of_task\": task_number,\n",
    "    \"walltime\": \"10:00\",\n",
    "}\n",
    "\n",
    "# Sets specific parameters for the job\n",
    "\n",
    "demo_job.set(executableFolder=\"git://fireabm\", \n",
    "             param={\"start_value\": local_start_value}, slurm=slurm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the job can be submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… job submitted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align:left\">id                      </th><th style=\"text-align:left\">maintainer   </th><th style=\"text-align:left\">hpc                   </th><th style=\"text-align:left\">executableFolder                       </th><th style=\"text-align:left\">dataFolder     </th><th style=\"text-align:left\">resultFolder  </th><th style=\"text-align:left\">param            </th><th style=\"text-align:left\">slurm              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align:left\">2021-08-16T14:27:18.000Z</td><td style=\"text-align:left\">git://fireabm</td><td style=\"text-align:left\">community_contribution</td><td style=\"text-align:left\">{&quot;num_of_task&quot;: 2, &quot;walltime&quot;: &quot;10:00&quot;}</td><td style=\"text-align:left\">16291420382ZGRa</td><td style=\"text-align:left\">              </td><td style=\"text-align:left\">keeling_community</td><td style=\"text-align:left\">{&quot;start_value&quot;: 20}</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<cybergis_compute_client.Job.Job at 0x7fc084db2450>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit job!\n",
    "\n",
    "demo_job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"view\"></a>\n",
    "## View and Download the CyberGIS-Compute Job Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job has been submitted, the `events()` and the `logs()` functions can be used to follow the job progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“® Job ID: 16291420382ZGRa\n",
      "ðŸ’» HPC: keeling_community\n",
      "ðŸ¤– Maintainer: community_contribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>types             </th><th>message                                                                                                                                                 </th><th>time                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>JOB_QUEUED        </td><td>job [16291420382ZGRa] is queued, waiting for registration                                                                                               </td><td>2021-08-16T14:27:18.000Z</td></tr>\n",
       "<tr><td>JOB_REGISTERED    </td><td>job [16291420382ZGRa] is registered with the supervisor, waiting for initialization                                                                     </td><td>2021-08-16T14:27:21.000Z</td></tr>\n",
       "<tr><td>SLURM_UPLOAD      </td><td>uploading files                                                                                                                                         </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SSH_UNZIP         </td><td>unzipping /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/executable.zip to /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/executable</td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SSH_RM            </td><td>removing /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/executable.zip                                                                        </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SSH_CREATE_FILE   </td><td>create file to /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/executable/job.json                                                             </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SLURM_MKDIR_RESULT</td><td>creating result folder                                                                                                                                  </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SLURM_SUBMIT      </td><td>submitting slurm job                                                                                                                                    </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>JOB_INIT          </td><td>job [16291420382ZGRa] is initialized, waiting for job completion                                                                                        </td><td>2021-08-16T14:27:27.000Z</td></tr>\n",
       "<tr><td>SSH_ZIP           </td><td>zipping /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/result to /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/result.zip          </td><td>2021-08-16T14:28:01.000Z</td></tr>\n",
       "<tr><td>SSH_SCP_DOWNLOAD  </td><td>get file from /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/result to /job_supervisor/data/root/1629142042S1eT                               </td><td>2021-08-16T14:28:01.000Z</td></tr>\n",
       "<tr><td>SSH_RM            </td><td>removing /data/keeling/a/cigi-gisolve/scratch/dev/16291420382ZGRa/result.zip                                                                            </td><td>2021-08-16T14:28:01.000Z</td></tr>\n",
       "<tr><td>JOB_ENDED         </td><td>job [16291420382ZGRa] finished                                                                                                                          </td><td>2021-08-16T14:28:01.000Z</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View job events\n",
    "\n",
    "demo_job.events(liveOutput=True, refreshRateInSeconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“® Job ID: 16291420382ZGRa\n",
      "ðŸ’» HPC: keeling_community\n",
      "ðŸ¤– Maintainer: community_contribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>message  </th><th>time                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style='text-align:left'>node id: 0, task id: 1, start number: 20, SEED: 21, result folder: /16291420382ZGRa/result\n",
       "\n",
       "/16291420382ZGRa/executable\n",
       "node id: 0, task id: 0, start number: 20, SEED: 20, result folder: /16291420382ZGRa/result\n",
       "\n",
       "/16291420382ZGRa/executable\n",
       "copying over files\n",
       "using FireABM_opt\n",
       "\n",
       "!! starting file parse at: 14:27:38\n",
       "using FireABM_opt\n",
       "\n",
       "!! starting file parse at: 14:27:38\n",
       "\n",
       "!! Working Directory:  /16291420382ZGRa/executable\n",
       "\n",
       "!! checking input parameters\n",
       "\n",
       "!! Working Directory:  /16291420382ZGRa/executab...[download for full log]          </td><td style='text-align:left'>2021-08-16T14:28:01.000Z</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View job logs\n",
    "\n",
    "demo_job.logs(liveOutput=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is complete, any results written to the `$results_folder` can be downloaded with the `downloadResultFolder()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file successfully downloaded under: ./1629142042S1eT.zip\n"
     ]
    }
   ],
   "source": [
    "# Download results\n",
    "\n",
    "outfile = demo_job.downloadResultFolder('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results folder is downloaded as a .zip file. The following commands can be used to create a new folder to hold all the results and to unzip thd downloaded .zip file to the new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for the results and unzip the results to the folder\n",
    "\n",
    "!mkdir results_dir\n",
    "!unzip -q -o $outfile -d results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clean\"></a>\n",
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it can be useful to clean up what has been downloaded. The following lines remove the results folder and the job file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to clean up results directory\n",
    "\n",
    "#!rm -r results_dir\n",
    "\n",
    "# Run to clean up results zip file\n",
    "\n",
    "#!rm $outfile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "## Steps for Creating your own Custom job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a Custom Monte Carlo style job you will need to follow these steps:\n",
    "1. Determine what script you want to run.\n",
    "1. Create a GitHub repository containing the script and any data needed for it to run.\n",
    "1. Create a shell script to create any needed directories and run the script based on input parameters. \n",
    "1. Create a manifest.json file containing the job information and specifying which top level script to run.\n",
    "1. Contact the CyberGIS team to submit your GitHub repository for approval.\n",
    "1. Once your GitHub repository has been approved, attempt to run your job from a notebook.\n",
    "1. Look at the job.stdout, job.stderr, and output files for any errors. If there are errors, you can make changes to the files in your GitHub repository and try to run the job again until it runs correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
